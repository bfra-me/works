---
description: APPLY when RECOMMENDING new Cursor rules to IMPROVE repository guidance
globs:
alwaysApply: false
---
# Repository Rule Recommender

<rule>
name: repo_rule_recommender
description: Systematic workflow for analyzing repositories and recommending appropriate Cursor rules
filters:
  - type: message
    pattern: "(?i)(recommend.*cursor rules|generate.*cursor rules|create.*rule.*based on|suggest.*cursor rules|analyze repo.*rules)"
  - type: context
    pattern: "cursor rule recommendations|repository analysis|rule generation|prompt_library|repository report"

actions:
  - type: suggest
    message: |
      # Repository Analysis and Cursor Rule Recommendation Workflow

      This workflow provides a systematic approach to analyzing repositories and suggesting appropriate Cursor rules. While ideal automation might use specialized tools, this workflow adapts to currently available tools like `Sequential Thinking`, `Repo Analyzer`, and file system operations.

      ## Step 1: Repository Analysis

      First, examine the repository structure and key technologies used. Use the [repo-analyzer](mdc:.cursor/rules/repo-analyzer.mdc) guidelines or `Sequential Thinking` to structure the analysis:

      ```javascript
      // Use sequentialthinking to break down the analysis process
      mcp_sequential_thinking_sequentialthinking({
        thought: "Analyzing repository structure (languages, frameworks, build tools, linting, testing, workflows)...",
        thoughtNumber: 1,
        totalThoughts: 3, // Adjust as needed
        nextThoughtNeeded: true
      });
      ```

      Key areas to analyze:
      1. **Core Technologies** - Languages, frameworks, libraries.
      2. **Project Structure** - Monorepo, organization.
      3. **Development Patterns** - Testing, linting, formatting, versioning.
      4. **Build/Deployment** - Build systems, CI/CD workflows.

      ## Step 2: Create Repository Summary

      Based on the analysis, create a concise repository summary:

      ```javascript
      // Example Summary (created manually or via Step 1 analysis)
      const repoSummary = `A TypeScript monorepo using pnpm workspaces...
      Uses ESLint, Prettier, Vitest.
      Implements Changesets and GitHub Actions CI/CD.`;
      ```

      ## Step 3: Identify Potential Rules

      Based on the summary and existing rules in [00-rule-index](mdc:.cursor/rules/00-rule-index.mdc), identify gaps or areas where guidance would be beneficial. Consider rules for:
      - Language-specific patterns (e.g., TypeScript)
      - Tool configuration/usage (e.g., ESLint, Prettier, Vitest, Changesets)
      - Workflow guidance (e.g., Development, CI/CD, API Design, Testing)
      - Monorepo navigation

      *(Note: Currently, automatic rule recommendation based on repo summary requires manual interpretation or AI reasoning, as specialized tools like `prompt_library` are not available.)*

      ## Step 4: Review Existing Rules

      Before creating new rules, check `.cursor/rules/` to avoid duplication:

      ```bash
      # List existing rules using list_dir tool
      # (AI action: call list_dir for .cursor/rules/)
      ```
      Compare potential new rules against the existing list.

      ## Step 5: Create New Rules

      For each needed rule that doesn't exist:
      1. Follow the [cursor-rules-creation](mdc:.cursor/rules/cursor-rules-creation.mdc) guide.
      2. Use the [rule-automation-script](mdc:.cursor/rules/rule-automation-script.mdc) for scaffolding if desired:
         ```bash
         # Use run_terminal_cmd tool
         ./scripts/create-cursor-rule.sh new-rule-name "Description..." "globs..."
         ```
      3. Manually edit the generated `.mdc` file to add filters, content, examples, and metadata.

      *(Note: Automatic rule content generation is not currently available via tools.)*

      ## Step 6: Test and Refine Rules

      After creating rules, test them:
      1. Open relevant files that *should* trigger the rule.
      2. Verify the rule appears as expected (auto-attached or suggested).
      3. Check if the content and examples are helpful.
      4. Refine the rule file (`edit_file`) as needed.

      ## Complete Workflow Example (Adapted)

      Here's an example adapting the workflow:

      ```javascript
      // 1. Analyze repository (using Sequential Thinking or Repo Analyzer guidelines)
      mcp_sequential_thinking_sequentialthinking({
        thought: "Analyzing repo: TypeScript monorepo, pnpm, ESLint, Prettier, Vitest, Changesets, GitHub Actions.",
        thoughtNumber: 1,
        totalThoughts: 3,
        nextThoughtNeeded: true
      });
      // ... subsequent thoughts refining analysis ...

      // 2. Create repository summary (result of analysis)
      const repoSummary = "TypeScript monorepo, pnpm workspaces, ESLint, Prettier, Vitest, Changesets, GitHub Actions.";

      // 3. Identify Potential Rules (AI/Manual Step)
      // AI suggests rules like: typescript-patterns, eslint-config-usage, prettier-config-usage, monorepo-structure, changeset-workflow, testing-practices, ci-cd-workflow.

      // 4. Examine existing rules
      // AI calls list_dir for .cursor/rules/
      // AI compares suggestions to existing rules.

      // 5. Create missing rules (Example: creating changeset-workflow)
      // AI uses run_terminal_cmd:
      // ./scripts/create-cursor-rule.sh changeset-workflow "FOLLOW when VERSIONING..." ".changeset/*.md"
      // AI then uses edit_file to populate the new changeset-workflow.mdc based on known best practices or user input.

      // 6. Test and refine rules (Manual / AI-assisted)
      // User opens a .changeset/ file, AI checks if changeset-workflow rule is suggested or attached.
      ```

      ## Using Repository Reports

      If you have a repository analysis report:
      1. Manually extract key technologies/structures.
      2. Use this summary in Step 3 to manually/AI-reason about needed rules.

      This adapted workflow emphasizes manual/AI reasoning where specific tools are unavailable, while still leveraging available tools for analysis and scaffolding.

      ## Related Rules

      - [repo-analyzer](mdc:.cursor/rules/repo-analyzer.mdc): Provides guidelines for the initial analysis step.
      - [cursor-rules-creation](mdc:.cursor/rules/cursor-rules-creation.mdc): The primary guide for authoring rule content.
      - [rule-automation-script](mdc:.cursor/rules/rule-automation-script.mdc): Can be used for scaffolding in Step 5.
      - [00-rule-index](mdc:.cursor/rules/00-rule-index.mdc): Used to check for existing rules in Step 4.
      - [mcp-tools-usage](mdc:.cursor/rules/mcp-tools-usage.mdc): For using tools like Sequential Thinking during analysis.

examples:
  - input: |
      Help me figure out what Cursor rules this project might need.
    output: |
      Okay, let's figure out what Cursor rules might be beneficial for this project. We'll follow a systematic workflow:

      **Step 1: Analyze Repository**
      I need to understand the project's technologies and structure. Can you tell me about the main languages, frameworks, tools (linting, testing, versioning), and workflows used? Or, I can start analyzing using `Sequential Thinking` and the `repo-analyzer` guidelines.

      ```javascript
      // Let's start the analysis
      mcp_sequential_thinking_sequentialthinking({
        thought: "Initial analysis: What are the primary languages, frameworks, and key tools visible in the workspace?",
        thoughtNumber: 1,
        totalThoughts: 4, // Estimate
        nextThoughtNeeded: true
      });
      ```

      **Step 2: Summarize Findings**
      Once the analysis is done (either through `Sequential Thinking` or your description), I'll create a summary like:
      `"This project is a [Language] [Type e.g., web app/library] using [Framework], with [Linter], [Formatter], [Tester], and [Versioning Tool]."`

      **Step 3: Identify Potential Rules**
      Based on the summary, I'll compare the technologies/workflows against the standard rules listed in the [00-rule-index](mdc:.cursor/rules/00-rule-index.mdc) and suggest areas where rules could be helpful (e.g., `[framework]-patterns`, `[linter]-config-usage`, `[versioning]-workflow`).

      **Step 4: Check Existing Rules**
      I'll check the `.cursor/rules/` directory to see which suggested rules already exist.
      ```bash
      # AI Action: List files in .cursor/rules/
      # (tool call: list_dir .cursor/rules/)
      ```

      **Step 5: Suggest Creation**
      For potentially useful rules that are missing, I can suggest creating them using the [rule-automation-script](mdc:.cursor/rules/rule-automation-script.mdc) or by following the [cursor-rules-creation](mdc:.cursor/rules/cursor-rules-creation.mdc) guide.

      Shall we start with Step 1 analysis?

metadata:
  priority: high
  version: 1.1
  tags:
    - repository-analysis
    - cursor-rules
    - workflow
    - recommendations
  changelog:
    - version: 1.1
      changes:
        - Added Related Rules section with bidirectional cross-references
    - version: 1.0
      changes:
        - Initial version
  last_updated: "2025-05-06"
</rule>
